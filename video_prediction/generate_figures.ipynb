{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup\n",
    "Modify `clargs` to point to the path of the model you wish to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clargs = '''--model_path ./results/phys101/001/model_400.pth \\\n",
    "    --num_inner_steps 1 \\\n",
    "    --n_future 20 \\\n",
    "    --horiz_flip \\\n",
    "    --test_set_length 78 \\\n",
    "    --train_set_length 311 \\\n",
    "    --reuse_lstm_eps \\\n",
    "    --seed 1612 \\\n",
    "    --data_root ./data/phys101/phys101/scenarios/ramp \\\n",
    "    --dataset phys101 \\\n",
    "    --n_past 2 \\\n",
    "    --tailor \\\n",
    "    --n_trials 1 \\\n",
    "    --only_twenty_degree \\\n",
    "    --frame_step 2 \\\n",
    "    --crop_upper_right 1080 \\\n",
    "    --center_crop 1080 \\\n",
    "    --batch_size 2 \\\n",
    "    --image_width 128 \\\n",
    "    --num_threads 4 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "import shlex  # for clargs in Jupyter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "import copy\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "import itertools\n",
    "import progressbar\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "import higher\n",
    "from lpips_pytorch import LPIPS\n",
    "\n",
    "from models.forward import predict_many_steps, tailor_many_steps\n",
    "from models.cn import replace_cn_layers, CNLayer\n",
    "from models.svg import SVGModel\n",
    "from models.embedding import ConservedEmbedding\n",
    "from utils import svg_crit\n",
    "print(f'PID: {os.getpid()}')\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "\n",
    "# NOTE: deterministic for debugging\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
    "parser.add_argument('--data_root', default='data', help='root directory for data')\n",
    "parser.add_argument('--model_path', default='', help='path to model')\n",
    "parser.add_argument('--baseline_model_path', default='', help='path to model')\n",
    "parser.add_argument('--seed', default=1, type=int, help='manual seed')\n",
    "parser.add_argument('--n_past', type=int, default=2, help='number of frames to condition on')\n",
    "parser.add_argument('--n_future', type=int, default=10, help='number of frames to predict')\n",
    "parser.add_argument('--num_threads', type=int, default=0, help='number of data loading threads')\n",
    "parser.add_argument('--dataset', default='bair', help='dataset to train with')\n",
    "parser.add_argument('--image_width', type=int, default=64, help='the height / width of the input image to network')\n",
    "parser.add_argument('--g_dim', type=int, default=128, help='dimensionality of encoder output vector and decoder input vector')\n",
    "parser.add_argument('--use_action', type=int, default=0, help='if true, train action-conditional model')\n",
    "parser.add_argument('--channels', default=3, type=int)\n",
    "parser.add_argument('--tailor', action='store_true', help='if true, perform tailoring')\n",
    "parser.add_argument('--num_inner_steps', type=int, default=1, help='how many tailoring steps?')\n",
    "parser.add_argument('--num_train_batch', type=int, default=-1, help='if -1, do all of them')\n",
    "parser.add_argument('--num_val_batch', type=int, default=-1, help='if -1, do all of them')\n",
    "parser.add_argument('--train_set_length', type=int, default=256, help='size of training set')\n",
    "parser.add_argument('--test_set_length', type=int, default=-1, help='size of test set')\n",
    "parser.add_argument('--learn_inner_lr', action='store_true', help='optimize inner LR in outer loop?')\n",
    "parser.add_argument('--n_trials', type=int, default=7, help='number of trials to average over')\n",
    "parser.add_argument('--emb_dim', type=int, default=8, help='dim for Emb')\n",
    "parser.add_argument('--inner_crit_mode', default='mse', help='mse or cosine')\n",
    "parser.add_argument('--inner_lr', type=float, default=-1, help='learning rate for inner optimizer')\n",
    "parser.add_argument('--val_inner_lr', type=float, default=-1, help='val. LR for inner opt (if -1, use orig.)')\n",
    "parser.add_argument('--svg_loss_kl_weight', type=float, default=0.0001, help='weighting factor for KL loss')\n",
    "parser.add_argument('--reuse_lstm_eps', action='store_true', help='correlated eps samples for prior & posterior?')\n",
    "parser.add_argument('--only_tailor_on_improvement', action='store_true', help='no outer update if no inner improvement')\n",
    "parser.add_argument('--stack_frames', action='store_true', help='stack every 2 frames channel-wise')\n",
    "parser.add_argument('--only_twenty_degree', action='store_true', help='for Phys101 ramp, only 20 degree setting?')\n",
    "parser.add_argument('--center_crop', type=int, default=1080, help='center crop param (phys101)')\n",
    "parser.add_argument('--crop_upper_right', type=int, default=1080, help='upper right crop param (phys101)')\n",
    "parser.add_argument('--frame_step', type=int, default=2, help='controls frame rate for Phys101')\n",
    "parser.add_argument('--num_emb_frames', type=int, default=1, help='number of frames to pass to the embedding')\n",
    "parser.add_argument('--horiz_flip', action='store_true', help='randomly flip phys101 sequences horizontally (p=.5)?')\n",
    "parser.add_argument('--save_warmstart_dataset', action='store_true', help='save_warmstart_dataset')\n",
    "parser.add_argument('--inner_opt_all_model_weights', action='store_true', help='optimize non-CN model weights in inner loop?')\n",
    "parser.add_argument('--adam_inner_opt', action='store_true', help='use Adam in inner loop?')\n",
    "\n",
    "clargs = shlex.split(clargs)\n",
    "\n",
    "opt = parser.parse_args(clargs)\n",
    "\n",
    "track_gen = True\n",
    "\n",
    "opt.n_eval = opt.n_past+opt.n_future\n",
    "opt.max_step = opt.n_eval\n",
    "\n",
    "print(\"Random Seed: \", opt.seed)\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "torch.cuda.manual_seed_all(opt.seed)\n",
    "dtype = torch.cuda.FloatTensor\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# --------- load a dataset ------------------------------------\n",
    "train_data, test_data = utils.load_dataset(opt)\n",
    "\n",
    "if (opt.num_train_batch == -1) or (len(train_data) // opt.batch_size < opt.num_train_batch):\n",
    "    opt.num_train_batch = len(train_data) // opt.batch_size\n",
    "if (opt.num_val_batch == -1) or (len(test_data) // opt.batch_size < opt.num_val_batch):\n",
    "    opt.num_val_batch = len(test_data) // opt.batch_size\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          num_workers=opt.num_threads,\n",
    "                          batch_size=opt.batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          pin_memory=True)\n",
    "test_loader = DataLoader(test_data,\n",
    "                         num_workers=opt.num_threads,\n",
    "                         batch_size=opt.batch_size,\n",
    "                         shuffle=False,\n",
    "                         drop_last=True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "\n",
    "def get_batch_generator(data_loader):\n",
    "    while True:\n",
    "        for sequence in data_loader:\n",
    "            if not opt.use_action:\n",
    "                batch = utils.normalize_data(opt, dtype, sequence)\n",
    "                yield batch\n",
    "            else:\n",
    "                images, actions = sequence\n",
    "                images = utils.normalize_data(opt, dtype, images)\n",
    "                actions = utils.sequence_input(actions.transpose_(0, 1), dtype)\n",
    "                yield images, actions\n",
    "\n",
    "training_batch_generator = get_batch_generator(train_loader)\n",
    "testing_batch_generator = get_batch_generator(test_loader)\n",
    "\n",
    "print('\\nDatasets loaded!')\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- plotting util fns --------------------------\n",
    "def combine_dims(a, start=2, count=2):\n",
    "    \"\"\" Reshapes numpy array a by combining count dimensions, \n",
    "        starting at dimension index start \"\"\"\n",
    "    s = a.transpose((0,2,1,3,4)).shape\n",
    "    return np.reshape(a.transpose((0,2,1,3,4)), s[:start] + (-1,) + s[start+count:])\n",
    "\n",
    "\n",
    "def conf_int(data, alpha=0.95, dist='t'):\n",
    "    if dist == 't':\n",
    "        return st.t.interval(alpha, data.shape[0]-1, loc=data.mean(axis=0), scale=st.sem(data, axis=0))\n",
    "    elif dist == 'norm':\n",
    "        return st.norm.interval(alpha, loc=data.mean(axis=0), scale=st.sem(data, axis=0))\n",
    "    elif dist == 'sem':\n",
    "        return data.mean(axis=0) - st.sem(data, axis=0), data.mean(axis=0) + st.sem(data, axis=0)\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "ckpt = torch.load(opt.model_path)\n",
    "_opt = ckpt['opt']\n",
    "\n",
    "# ---------------- set the options ----------------------------\n",
    "if hasattr(_opt, 'num_emb_frames'):\n",
    "    opt.num_emb_frames = _opt.num_emb_frames\n",
    "opt.dataset = _opt.dataset\n",
    "opt.last_frame_skip = _opt.last_frame_skip\n",
    "opt.channels = _opt.channels\n",
    "opt.image_width = _opt.image_width\n",
    "if hasattr(_opt, 'inner_crit_compare_to'):\n",
    "    opt.inner_crit_compare_to = _opt.inner_crit_compare_to\n",
    "\n",
    "# ---------------- load the models ----------------------------\n",
    "if 'svg_model' in ckpt.keys():\n",
    "    if opt.inner_lr == -1:\n",
    "        opt.inner_lr = _opt.inner_lr\n",
    "    try:\n",
    "        if opt.val_inner_lr == -1:\n",
    "            opt.val_inner_lr = _opt.val_inner_lr\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    opt.inner_crit_mode = _opt.inner_crit_mode\n",
    "    opt.svg_loss_kl_weight = _opt.svg_loss_kl_weight\n",
    "    svg_model = ckpt['svg_model']\n",
    "    print('\\nSVG model with pre-trained weights loaded!')\n",
    "else:\n",
    "    svg_model = utils.modernize_model(opt.model_path, opt)\n",
    "    print('\\nOld SVG model with pre-trained weights loaded and modernized!')\n",
    "val_inner_lr = opt.inner_lr\n",
    "if opt.val_inner_lr != -1:\n",
    "    val_inner_lr = opt.val_inner_lr\n",
    "replace_cn_layers(svg_model.encoder, batch_size=opt.batch_size)\n",
    "replace_cn_layers(svg_model.decoder, batch_size=opt.batch_size)\n",
    "svg_model.frame_predictor.batch_size = opt.batch_size\n",
    "svg_model.posterior.batch_size = opt.batch_size\n",
    "svg_model.prior.batch_size = opt.batch_size\n",
    "opt.only_cn_decoder = False\n",
    "\n",
    "svg_model.cuda()\n",
    "emb = svg_model.emb\n",
    "svg_model.eval()\n",
    "\n",
    "norm_trnfm = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "\n",
    "lpips = LPIPS(\n",
    "    net_type='alex',  # choose a network type from ['alex', 'squeeze', 'vgg']\n",
    "    version='0.1'  # Currently, v0.1 is supported\n",
    ").cuda()\n",
    "\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation loop\n",
    "If using cached metrics, you can skip this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('starting eval loop...')\n",
    "all_tailor_ssims = []\n",
    "all_tailor_psnrs = []\n",
    "all_tailor_mses = []\n",
    "all_tailor_lpips = []\n",
    "all_val_inner_losses = []\n",
    "all_val_svg_losses = []\n",
    "all_gen = []\n",
    "all_outer_losses = []\n",
    "\n",
    "for trial_num in range(opt.n_trials):\n",
    "    print(f'TRIAL {trial_num}')\n",
    "    \n",
    "    tailor_ssims = []\n",
    "    tailor_psnrs = []\n",
    "    tailor_mses = []\n",
    "    tailor_lpips = []\n",
    "    val_inner_losses = []\n",
    "    val_svg_losses = []\n",
    "    val_outer_loss = 0.\n",
    "    \n",
    "    for batch_num in tqdm(range(opt.num_val_batch)):\n",
    "        batch = next(testing_batch_generator)\n",
    "\n",
    "        # tailoring pass\n",
    "        gen_seq, mus, logvars, mu_ps, logvar_ps = tailor_many_steps(\n",
    "            svg_model, batch, opt=opt, track_higher_grads=False,\n",
    "            mode='eval',\n",
    "            # extra kwargs\n",
    "            inner_crit_mode=opt.inner_crit_mode,\n",
    "            reuse_lstm_eps=opt.reuse_lstm_eps,\n",
    "            val_inner_lr=val_inner_lr,\n",
    "            svg_losses=val_svg_losses,\n",
    "            tailor_losses=val_inner_losses,\n",
    "            tailor_ssims=tailor_ssims,\n",
    "            tailor_psnrs=tailor_psnrs,\n",
    "            tailor_mses=tailor_mses,\n",
    "            only_cn_decoder=opt.only_cn_decoder,\n",
    "            adam_inner_opt=opt.adam_inner_opt,\n",
    "        )\n",
    "        \n",
    "        if track_gen:\n",
    "            all_gen.append([f.detach().cpu() for f in gen_seq])\n",
    "        \n",
    "        # LPIPS\n",
    "        with torch.no_grad():\n",
    "            lpips_scores = [[lpips(norm_trnfm(b[_idx]), norm_trnfm(g[_idx])).detach().cpu().item() for b, g in zip(batch[opt.n_past:], gen_seq[opt.n_past:])] for _idx in range(batch[0].shape[0])]\n",
    "            tailor_lpips.append(lpips_scores)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outer_loss = svg_crit(gen_seq, batch, mus, logvars, mu_ps, logvar_ps, opt)\n",
    "\n",
    "        val_outer_loss += outer_loss.detach().cpu().numpy().item()\n",
    "\n",
    "    all_val_inner_losses.append([sum(x) / (opt.num_val_batch) for x in zip(*val_inner_losses)])\n",
    "    all_val_svg_losses.append([sum(x) / (opt.num_val_batch) for x in zip(*val_svg_losses)])\n",
    "    all_tailor_ssims.append(copy.deepcopy(tailor_ssims))\n",
    "    all_tailor_psnrs.append(copy.deepcopy(tailor_psnrs))\n",
    "    all_tailor_mses.append(copy.deepcopy(tailor_mses))\n",
    "    all_tailor_lpips.append(copy.deepcopy(tailor_lpips))\n",
    "    all_outer_losses.append(val_outer_loss / (opt.num_val_batch))\n",
    "    \n",
    "    print(f'Model {trial_num}:')\n",
    "    print(np.array(all_val_svg_losses[-1]).shape)\n",
    "    print(f'\\tOuter SVG loss:   {np.array(all_val_svg_losses[-1]).mean(axis=(0))}')\n",
    "    print(f'\\tInner VAL loss:   {np.array(all_val_inner_losses[-1]).mean(axis=(0))}')\n",
    "    print(f'\\tOuter VAL loss:   {all_outer_losses[-1]}')\n",
    "    print(f'\\tOuter SSIM:       {np.array(all_tailor_ssims[-1]).mean(axis=(0,1,-2))}\\n\\t\\tmean: {np.array(all_tailor_ssims[-1]).mean()}')\n",
    "    print(f'\\tOuter PSNR:       {np.array(all_tailor_psnrs[-1]).mean(axis=(0,1,-2))}\\n\\t\\tmean: {np.array(all_tailor_psnrs[-1]).mean()}')\n",
    "    print(f'\\tOuter MSE:        {np.array(all_tailor_mses[-1]).mean(axis=(0,1,-2))}\\n\\t\\tmean: {np.array(all_tailor_mses[-1]).mean()}')\n",
    "\n",
    "all_tailor_ssims = np.array(all_tailor_ssims)\n",
    "all_tailor_psnrs = np.array(all_tailor_psnrs)\n",
    "all_tailor_mses = np.array(all_tailor_mses)\n",
    "all_tailor_lpips = np.array(all_tailor_lpips)[:,:,None,:,:]\n",
    "all_val_inner_losses = np.array(all_val_inner_losses)\n",
    "all_val_svg_losses = np.array(all_val_svg_losses)\n",
    "all_outer_losses = np.array(all_outer_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load cached metrics\n",
    "the loaded metrics will be shaped like the following:\n",
    "```\n",
    "all_tailor_ssims.shape:               (n_trials, num_batches, num_inner_steps+1, batch_size, n_future)\n",
    "combine_dims(all_tailor_ssims).shape: (n_trials, num_inner_steps+1, num_batches*batch_size, n_future)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_use_cached_noether_metrics = True\n",
    "\n",
    "# specify ID(s) of the training run(s) and the learning rate(s)\n",
    "noether_experiment_ids = [\n",
    "    ('001', .001),\n",
    "    ('002', .001),\n",
    "    # etc.\n",
    "]\n",
    "baseline_experiment_ids = [\n",
    "    '101',\n",
    "    '102',\n",
    "    # etc.\n",
    "]\n",
    "\n",
    "cache_steps = 1  # number of inner steps\n",
    "baseline_eval_epoch = 2  # model checkpoint epoch\n",
    "noether_eval_epoch = baseline_eval_epoch\n",
    "num_trials_per_model = 1  # number of trials for evaluation loop\n",
    "baseline_num_trials_per_model = 1\n",
    "cache_noether_use_adam = False  # Adam or SGD?\n",
    "\n",
    "print(f'noether_experiment_ids: {noether_experiment_ids}')\n",
    "\n",
    "svg_all_base_tailor_ssims = []\n",
    "svg_all_base_tailor_psnrs = []\n",
    "svg_all_base_tailor_mses = []\n",
    "svg_all_base_tailor_lpips = []\n",
    "for exp_id in baseline_experiment_ids:\n",
    "    fname = \\\n",
    "        f'eval_metrics/cached_metrics_id{exp_id}-ep{int(baseline_eval_epoch)}-trials{baseline_num_trials_per_model}.npz'\n",
    "    svg_baseline_metrics = np.load(fname)\n",
    "    svg_all_base_tailor_ssims.append(svg_baseline_metrics['all_base_tailor_ssims'].mean(axis=0, keepdims=True))\n",
    "    svg_all_base_tailor_psnrs.append(svg_baseline_metrics['all_base_tailor_psnrs'].mean(axis=0, keepdims=True))\n",
    "    svg_all_base_tailor_mses.append(svg_baseline_metrics['all_base_tailor_mses'].mean(axis=0, keepdims=True))\n",
    "    svg_all_base_tailor_lpips.append(svg_baseline_metrics['all_base_tailor_lpips'].mean(axis=0, keepdims=True))\n",
    "    print(f'loaded baseline metrics from {fname}')\n",
    "\n",
    "noether_tailor_ssims = []\n",
    "noether_tailor_psnrs = []\n",
    "noether_tailor_mses = []\n",
    "noether_tailor_lpips = []\n",
    "noether_val_svg_losses = []\n",
    "noether_val_inner_losses = []\n",
    "\n",
    "actual_noether_experiment_ids = []\n",
    "\n",
    "for exp_id, cache_lr in noether_experiment_ids:\n",
    "    fname = \\\n",
    "        f'eval_metrics/cached_metrics_id{exp_id}-ep{int(baseline_eval_epoch)}'\n",
    "    fname += f'-trials{num_trials_per_model}'\n",
    "    if cache_lr is not None and cache_steps is not None:\n",
    "        fname += f'-lr{cache_lr}'\n",
    "        fname += f'-steps{cache_steps}'\n",
    "    if cache_noether_use_adam:\n",
    "        fname += '-adam'\n",
    "    fname += '.npz'\n",
    "    if os.path.isfile(fname):\n",
    "        svg_baseline_metrics = np.load(fname)\n",
    "        noether_tailor_ssims.append(svg_baseline_metrics['all_base_tailor_ssims'].mean(axis=0, keepdims=True))\n",
    "        noether_tailor_psnrs.append(svg_baseline_metrics['all_base_tailor_psnrs'].mean(axis=0, keepdims=True))\n",
    "        noether_tailor_mses.append(svg_baseline_metrics['all_base_tailor_mses'].mean(axis=0, keepdims=True))\n",
    "        noether_tailor_lpips.append(svg_baseline_metrics['all_base_tailor_lpips'].mean(axis=0, keepdims=True))\n",
    "        if 'all_val_svg_losses' in svg_baseline_metrics and 'all_val_inner_losses' in svg_baseline_metrics:\n",
    "            noether_val_svg_losses.append(svg_baseline_metrics['all_val_svg_losses'])\n",
    "            noether_val_inner_losses.append(svg_baseline_metrics['all_val_inner_losses'])\n",
    "        print(f'loaded Noether Network metrics from {fname}')\n",
    "        actual_noether_experiment_ids.append(exp_id)\n",
    "    else:\n",
    "        print(f'File {fname} does not exist!')\n",
    "\n",
    "noether_experiment_ids = actual_noether_experiment_ids\n",
    "\n",
    "svg_all_base_tailor_ssims = np.concatenate(svg_all_base_tailor_ssims)\n",
    "svg_all_base_tailor_psnrs = np.concatenate(svg_all_base_tailor_psnrs)\n",
    "svg_all_base_tailor_mses = np.concatenate(svg_all_base_tailor_mses)\n",
    "svg_all_base_tailor_lpips = np.concatenate(svg_all_base_tailor_lpips)\n",
    "\n",
    "if _use_cached_noether_metrics:\n",
    "    all_tailor_ssims = np.concatenate(noether_tailor_ssims)\n",
    "    all_tailor_psnrs = np.concatenate(noether_tailor_psnrs)\n",
    "    all_tailor_mses = np.concatenate(noether_tailor_mses)\n",
    "    all_tailor_lpips = np.concatenate(noether_tailor_lpips)\n",
    "    all_val_inner_losses = np.concatenate(noether_val_inner_losses)\n",
    "    all_val_svg_losses = np.concatenate(noether_val_svg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot evaluation metrics vs. prediction horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "num_epochs = int(opt.model_path.split('/')[-1].split('_')[-1].split('.')[0])\n",
    "experiment_id = opt.model_path.split('/')[-2]\n",
    "plot_super_title = f\"SVG baseline (400 ep) vs. meta-tailored (90 more epochs) on {opt.dataset} ({opt.image_width}x{opt.image_width})\"\n",
    "plot_super_title = f\"SVG ({experiment_id}) meta-trained for {num_epochs} epoch(s)\"\n",
    "plot_super_title = f\"Physics 101: real-world video prediction\\n\"\n",
    "\n",
    "_title_size = 30\n",
    "_label_size = 20\n",
    "_legend_size = 14\n",
    "_tick_size = 14\n",
    "\n",
    "ci_alpha = 0.95\n",
    "base_label = 'naive baseline'\n",
    "base_label = 'SVG (more steps)'\n",
    "svg_label = 'SVG baseline'\n",
    "plot_baseline = True\n",
    "tailor_plot_idx = [1, 99]  # indices of inner steps to show (if they exist)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ssim_mean = combine_dims(all_tailor_ssims)\n",
    "psnr_mean = combine_dims(all_tailor_psnrs)\n",
    "mse_mean =  combine_dims(all_tailor_mses)\n",
    "lpips_mean =  combine_dims(all_tailor_lpips)\n",
    "\n",
    "print(ssim_mean.shape)\n",
    "\n",
    "if plot_baseline:\n",
    "    svg_base_ssim_mean = combine_dims(svg_all_base_tailor_ssims)[:,-1,:,:]\n",
    "    svg_base_psnr_mean = combine_dims(svg_all_base_tailor_psnrs)[:,-1,:,:]\n",
    "    svg_base_mse_mean =  combine_dims(svg_all_base_tailor_mses)[:,-1,:,:]\n",
    "    svg_base_lpips_mean =  combine_dims(svg_all_base_tailor_lpips)[:,-1,:,:]\n",
    "\n",
    "clrs = sns.color_palette('husl', ssim_mean.shape[1]+1)\n",
    "clrs[-1] = 'black'\n",
    "noether_color = '#2ca02c' # green\n",
    "base_color = '#ff7f0e' # orange\n",
    "outer_clrs = sns.color_palette('husl', 3)\n",
    "\n",
    "fig = plt.figure(figsize=(24, 4))\n",
    "gs = GridSpec(1, 4, figure=fig)\n",
    "ax00 = fig.add_subplot(gs[0,3])\n",
    "ax01 = fig.add_subplot(gs[0,2])\n",
    "ax11 = fig.add_subplot(gs[0,0])\n",
    "ax10 = fig.add_subplot(gs[0,1])\n",
    "\n",
    "for ax in ax00, ax01, ax10, ax11:\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis='x', labelsize=_tick_size)\n",
    "    ax.tick_params(axis='y', labelsize=_tick_size)\n",
    "\n",
    "ax10.ticklabel_format(style='sci', scilimits=(0,0), axis='y')\n",
    "ax10.yaxis.offsetText.set_fontsize(_tick_size)\n",
    "\n",
    "ax00.set_title('Test SSIM ⬆️', fontsize=_title_size)\n",
    "x_ax = np.arange(opt.n_past+1, opt.n_past+1+ssim_mean.shape[-1])\n",
    "for step in range(ssim_mean.shape[1]):\n",
    "    mod_label = f'Noether Network ({step} step)'\n",
    "    if step in tailor_plot_idx:\n",
    "        ax00.plot(x_ax, ssim_mean[:,step,:,:].mean(axis=0).mean(axis=-2),\n",
    "                  color=noether_color,\n",
    "                  label=mod_label)\n",
    "        lb, ub = conf_int(ssim_mean[:,step,:,:].mean(axis=-2), dist='sem')\n",
    "        ax00.fill_between(x_ax, lb, ub, alpha=0.3, color=noether_color)\n",
    "\n",
    "if plot_baseline:\n",
    "    ax00.plot(x_ax, svg_base_ssim_mean.mean(axis=0).mean(-2), color=base_color, label=svg_label)\n",
    "    lb, ub = conf_int(svg_base_ssim_mean.mean(axis=-2), dist='sem')\n",
    "    ax00.fill_between(x_ax, lb, ub, alpha=0.3, color=base_color)\n",
    "\n",
    "ax00.legend(prop={'size': _legend_size})\n",
    "ax00.set_xlabel('Prediction horizon', fontsize=_label_size)\n",
    "\n",
    "ax01.set_title('Test PSNR ⬆️', fontsize=_title_size)\n",
    "for step in range(ssim_mean.shape[1]):\n",
    "    mod_label = f'tailored ({step} step)'\n",
    "    if step in tailor_plot_idx:\n",
    "        ax01.plot(x_ax, psnr_mean[:,step,:,:].mean(axis=0).mean(axis=-2), color=noether_color)\n",
    "        lb, ub = conf_int(psnr_mean[:,step,:,:].mean(axis=-2), dist='sem')\n",
    "        ax01.fill_between(x_ax, lb, ub, alpha=0.3, color=noether_color)\n",
    "\n",
    "if plot_baseline:\n",
    "    ax01.plot(x_ax, svg_base_psnr_mean.mean(axis=0).mean(-2), color=base_color)\n",
    "    lb, ub = conf_int(svg_base_psnr_mean.mean(axis=-2), dist='sem')\n",
    "    ax01.fill_between(x_ax, lb, ub, alpha=0.3, color=base_color)\n",
    "\n",
    "ax01.set_xlabel('Prediction horizon', fontsize=_label_size)\n",
    "ax10.set_title('Test MSE ⬇️', fontsize=_title_size)\n",
    "for step in range(ssim_mean.shape[1]):\n",
    "    mod_label = f'tailored ({step} step)'\n",
    "    if step in tailor_plot_idx:\n",
    "        ax10.plot(x_ax, mse_mean[:,step,:,:].mean(axis=0).mean(axis=-2),\n",
    "                  color=noether_color,\n",
    "                  label=mod_label)\n",
    "        lb, ub = conf_int(mse_mean[:,step,:,:].mean(axis=-2), dist='sem')\n",
    "        ax10.fill_between(x_ax, lb, ub, alpha=0.3, color=noether_color)  # color=clrs[step])\n",
    "\n",
    "if plot_baseline:\n",
    "    ax10.plot(x_ax, svg_base_mse_mean.mean(axis=0).mean(-2), color=base_color)\n",
    "    lb, ub = conf_int(svg_base_mse_mean.mean(-2), dist='sem')\n",
    "    ax10.fill_between(x_ax, lb, ub, alpha=0.3, color=base_color)\n",
    "\n",
    "ax10.set_xlabel('Prediction horizon', fontsize=_label_size)\n",
    "\n",
    "ax11.set_title('Test LPIPS ⬇️', fontsize=_title_size)\n",
    "mod_label = f'tailored ({step} step)'\n",
    "ax11.plot(x_ax, lpips_mean[:,0,:,:].mean(axis=0).mean(axis=-2), color=noether_color)\n",
    "lb, ub = conf_int(lpips_mean[:,0,:,:].mean(axis=-2), dist='sem')\n",
    "ax11.fill_between(x_ax, lb, ub, alpha=0.3, color=noether_color)  # color=clrs[step])\n",
    "\n",
    "if plot_baseline:\n",
    "    ax11.plot(x_ax, svg_base_lpips_mean.mean(axis=0).mean(-2), color=base_color)\n",
    "    lb, ub = conf_int(svg_base_lpips_mean.mean(-2), dist='sem')\n",
    "    ax11.fill_between(x_ax, lb, ub, alpha=0.3, color=base_color)\n",
    "\n",
    "ax11.set_xlabel('Prediction horizon', fontsize=_label_size)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot {inner, outer} loss vs. inner step\n",
    "This is only interesting for evaluation runs where you take many inner steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "_title_size = 21\n",
    "_label_size = 18\n",
    "_legend_size = 14\n",
    "_tick_size = 14\n",
    "\n",
    "plt_steps = all_val_inner_losses.shape[1]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(6, 10))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='x', labelsize=_tick_size)\n",
    "    ax.tick_params(axis='y', labelsize=_tick_size)\n",
    "axes[1].ticklabel_format(style='sci', scilimits=(0,0), axis='y')\n",
    "axes[1].yaxis.offsetText.set_fontsize(_tick_size)\n",
    "\n",
    "axes[0].plot(all_val_inner_losses.mean(0)[:plt_steps])\n",
    "axes[1].plot(all_val_svg_losses.mean(0)[:plt_steps])\n",
    "\n",
    "lb, ub = conf_int(all_val_inner_losses[:,:plt_steps], dist='sem')\n",
    "axes[0].fill_between(np.arange(0,plt_steps), lb, ub, alpha=0.3,)\n",
    "\n",
    "lb, ub = conf_int(all_val_svg_losses[:,:plt_steps], dist='sem')\n",
    "axes[1].fill_between(np.arange(0,plt_steps), lb, ub, alpha=0.3,)\n",
    "\n",
    "axes[0].set_title('Inner loss vs. Inner step', fontsize=_title_size)\n",
    "axes[1].set_title('Outer loss vs. Inner step', fontsize=_title_size)\n",
    "axes[0].set_ylabel('Inner loss', fontsize=_label_size)\n",
    "axes[1].set_ylabel('Outer loss', fontsize=_label_size)\n",
    "axes[0].set_xlabel('Inner step', fontsize=_label_size)\n",
    "axes[1].set_xlabel('Inner step', fontsize=_label_size)\n",
    "\n",
    "axes[0].set_ylim(bottom=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM\n",
    "This section contains code to produce Grad-CAM heatmaps to visualize the \"important\" regions of frames for each dimension of the embedding (either in the embedding space or in PCA coordinates, which is useful for large embeddings).\n",
    "You'll need to run the evaluation loop earlier in the notebook to populate `all_gen` with the predicted frames for all of the sequences in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_all = []\n",
    "for batch_num in tqdm(range(opt.num_val_batch)):\n",
    "    batch = next(testing_batch_generator)\n",
    "    gt_all.append(batch)\n",
    "gt_catted = torch.stack([torch.cat([gt_all[_i][t] for _i in range(len(gt_all))]) for t in range(len(gt_all[0]))]).cpu()\n",
    "\n",
    "gc_all_gen = torch.stack([torch.cat([all_gen[_i][t] for _i in range(len(all_gen))]) for t in range(len(all_gen[0]))])\n",
    "gt_catted.shape, gc_all_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_seq = True\n",
    "grad_cam_seq_id = 17\n",
    "\n",
    "batch = [fr for fr in gt_catted[17:19]]  # for single time step, many sequences\n",
    "if single_seq:\n",
    "    batch = [fr for fr in gt_catted[:,grad_cam_seq_id:grad_cam_seq_id+1]]  # for all time steps, single sequence\n",
    "\n",
    "stacked_batch = []\n",
    "for i in range(1, len(batch)):\n",
    "    stacked_batch.append(torch.cat((batch[i-1], batch[i]), dim=1))\n",
    "if not single_seq:\n",
    "    stacked_batch = [fr.unsqueeze(0) for fr in stacked_batch[0]]\n",
    "len(stacked_batch), stacked_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbWrapper(nn.Module):\n",
    "    def __init__(self, emb, pca_model):\n",
    "        super().__init__()\n",
    "        self.emb = emb\n",
    "        self.pca_model = pca_model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_emb = self.emb(X)\n",
    "        X_pca = self.transform_torch(X_emb)\n",
    "        return X_pca\n",
    "    \n",
    "    def transform_torch(self, X):\n",
    "        if self.pca_model.mean_ is not None:\n",
    "            X = X - torch.from_numpy(self.pca_model.mean_).cuda()\n",
    "        X_transformed = torch.mm(X, torch.from_numpy(self.pca_model.components_.T).cuda())\n",
    "        if self.pca_model.whiten:\n",
    "            X_transformed /= torch.from_numpy(np.sqrt(self.pca_model.explained_variance_)).cuda()\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PCA = True\n",
    "\n",
    "emb = svg_model.emb\n",
    "\n",
    "if USE_PCA:\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    debug_loader = DataLoader(test_data,\n",
    "                             num_workers=opt.num_threads,\n",
    "                             batch_size=78,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True,\n",
    "                             pin_memory=True)\n",
    "\n",
    "    debug_batch_generator = get_batch_generator(debug_loader)\n",
    "    dbatch = next(debug_batch_generator)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        stacked_dbatch = []\n",
    "        for i in range(1, len(dbatch)):\n",
    "            stacked_dbatch.append(torch.cat((dbatch[i-1], dbatch[i]), dim=1))\n",
    "        all_dembs = [emb(frame).detach().cpu() for frame in stacked_dbatch]  # len(embs) = len(gen_seq) - 1\n",
    "\n",
    "    dembs = torch.cat(all_dembs[2:])\n",
    "    my_model = PCA(n_components=6)\n",
    "    my_model.fit_transform(dembs.numpy())\n",
    "    print(my_model.explained_variance_ratio_.cumsum())\n",
    "\n",
    "    emb = EmbWrapper(copy.deepcopy(svg_model.emb), my_model)\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import cv2\n",
    "\n",
    "if hasattr(emb, 'emb'):\n",
    "    target_layer = emb.emb.layer2[-2]\n",
    "    grad_cam_emb_dim = emb.pca_model.n_components\n",
    "    print('using wrapper')\n",
    "else:\n",
    "    target_layer = emb.layer2[-2]\n",
    "    grad_cam_emb_dim = emb.fc1.out_features\n",
    "    print('using emb directly')\n",
    "cam_model = GradCAM(model=emb, target_layer=target_layer, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(50, 300))\n",
    "ax = plt.gca()\n",
    "ax.axes.xaxis.set_ticks([])\n",
    "ax.axes.yaxis.set_ticks([])\n",
    "\n",
    "cams = []\n",
    "visualizations = []\n",
    "\n",
    "for j in tqdm(range(len(stacked_batch))):\n",
    "    in_tensor = stacked_batch[j]\n",
    "    dim_cams = []\n",
    "    dim_visualizations = []\n",
    "    for dim in range(grad_cam_emb_dim):\n",
    "        cam = cam_model(\n",
    "            input_tensor=in_tensor,\n",
    "            target_category=dim,\n",
    "        )\n",
    "        converted_cam = cv2.cvtColor(cam[0], cv2.COLOR_GRAY2BGR)\n",
    "        visualization = show_cam_on_image(\n",
    "            in_tensor[0,:3].cpu().numpy().transpose((1,2,0)),\n",
    "            converted_cam,\n",
    "            use_rgb=True,\n",
    "        )\n",
    "        dim_visualizations.append(visualization)\n",
    "        dim_cams.append(cam)\n",
    "    visualizations.append(dim_visualizations)\n",
    "    cams.append(dim_cams)\n",
    "\n",
    "plt.imshow(np.concatenate([np.concatenate(v, 1) for v in visualizations], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "gif_path = './grad_cam/'\n",
    "os.makedirs(gif_path, exist_ok=True)\n",
    "gif_frames = [np.concatenate(v, 1) for v in visualizations]\n",
    "imageio.mimsave(gif_path + f'grad_cam_seq{grad_cam_seq_id}.gif', gif_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-svg]",
   "language": "python",
   "name": "conda-env-.conda-svg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
